Whisper Hindi ASR Model
#Overview
The Whisper Hindi ASR (Automatic Speech Recognition) model is developed as part of the internship project at IIT Bombay. It utilizes the KathBath dataset, a comprehensive collection of speech samples in Hindi, for training. The model is designed to accurately transcribe spoken Hindi into text using advanced deep learning techniques.

Model Architecture
The Whisper model employs a Transformer sequence-to-sequence architecture, which is trained on various speech processing tasks, including multilingual speech recognition, speech translation, spoken language identification, and voice activity detection. By jointly representing these tasks as a sequence of tokens to be predicted by the decoder, the model can replace many stages of a traditional speech-processing pipeline.

Dataset
The KathBath dataset serves as a crucial foundation for training the Whisper model. It encompasses diverse speech samples sourced from different regions, covering a wide range of topics and conversational styles. This diversity enables the model to generalize well across various real-world scenarios, ensuring robust performance in different contexts.

Evaluation Metric: Word Error Rate (WER)
The Word Error Rate (WER) is a metric used to evaluate the performance of automatic speech recognition (ASR) systems. It measures the disparity between the transcribed output generated by the ASR system and the reference or ground truth transcription. WER is calculated as the ratio of the total number of errors (insertions, deletions, and substitutions) required to align the transcribed text with the reference text, divided by the total number of words in the reference text. Lower WER values indicate higher accuracy, with a perfect score of 0 indicating an exact match between the transcribed and reference texts.

Implementation and Usage
To implement and use the Whisper Hindi ASR model, follow these steps:

Install the Whisper package:
bash
Copy code
pip install -U openai-whisper
Alternatively, install the latest commit from the GitHub repository:
bash
Copy code
pip install git+https://github.com/openai/whisper.git 
Ensure that ffmpeg is installed on your system using the appropriate package manager for your operating system.
Train the model using the KathBath dataset or use pre-trained weights for inference.
Test Dataset
For evaluating the performance of the Whisper model and calculating the Word Error Rate (WER) for the KathBath dataset, you can use the test dataset provided at the following link:
GV_Eval_3h.tar.gz
